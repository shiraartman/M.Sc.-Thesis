# -*- coding: utf-8 -*-
"""NGS_analysis_get_nucleotides.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dsbVYEH22NRgQPwgBxn_mLXxcSL2cBLm

This is a pipeline to analyze NGS data derived from phage display.

General instructions:
- FASTQ files must be extracted from their 'gz' compressed files.
- FASTQ files are to be located in the same Google Drive account that is logged into Google Colab.
- Google Drive must be 'mounted' to Google Colab: this can be accomplished by clicking the directory symbol on the left panel and then clicking the Google Drive directory icon (the most right icon under 'Files'). You should now see the 'drive' directory. Click on it and then select 'MyDrive'. This now should show you Google Drive.
- Navigate to the directory where your FASTQ files are located, right-click the relevant FASTQ file, and choose 'copy path'.
- Paste the copied path into either FASTQ_R1_path' and 'FASTQ_R1_path', respectively. NOTE: the path name must be found between '' - i.e. 'pathname'.
- To activate each coding window, press the 'play' button found on the top left panel, or simply press shift + enter keys (in Mac command + enter).
- You will see the running process below the activated window. When the window has completed its run time (you should see a green vi sign at the upper part of the window), then you should proceed to the next window.
- **IMPORTANT** - Order is important! Each window must be activated before moving on to the next. Multiple windows cannot be activated simultaneously.
- Open the "variables" tab before running the code, to make sure the variables are updated as you run the code.
- For phage display analysis, paired-end reads are an overkill; single-end reads are enough. Therefore, if you performed a paired-end sequencing, you may ignore the R2 file (this is why all commands regarding R2 are commented).

**The pipeline is performed as follows:**
1. Data parsing of reads into a pandas DataFrame.
**Filtration steps:**
2. Slice sequences with expected length.
3. Slice sequences with an exact alignment to the upstream and downstream sequences found flanked to the variable region, where the distance between these sequences must be 36nts.
**Slicing variable regions steps:**
4. Identify the index where the variable region starts in each sequence (this varies between reads as we added 1-3 N base at 5' and 3' of the reads).
5. Slice 36nts from the index (downstream or upstream for forward and reverse,respectively).
6. add all sequences to a pandas DataFrame, while copying the reverse variable regions as reverse-complement!
**Filter variable regions:**
7. Compare the forward and reverse variable regions (which are expected to align perfectly to each other). Pairs that do not align, are omitted from the data.
8. Translate into AAs all filtered variable sequences.

# New Section
"""

# Mount Google Drive to Google Colab

from google.colab import drive
drive.mount('/content/drive')

# Flanking sequences of var region, may vary between different experiments

forward_seq_up = 'ctttctattctcacTCT'.upper()
forward_seq_down = 'GGTGGAGGT'.upper()
reverse_seq_up = "ACCTCCACC".upper()
reverse_seq_down = "AGAGTGAGA".upper()

# These sequences were extracted from "M13KE Random seq. restriction site" found on Energy Lab's Benchling account. They flank the variable region.
#(https://benchling.com/energylabtau/f/lib_BiKyftAg-cloning-phage-vector-for-elisa/seq_CchERKCy-m13ke-random-seq-restriction-site/edit)

# Enter your FASTA path here!
FASTQ_R1_path = "/content/drive/MyDrive/Iftach lab members/Shira Artman/Phage display - peptides/NGS/210922 Illumina run - FASTQ files/T3_S3_L001_R1_001.fastq"
#FASTQ_R2_path = "/content/drive/MyDrive/Iftach lab members/Shira Artman/NGS/F3_S1_L001_R2_001.fastq"

from google.colab import drive
drive.mount('/content/drive')

# Library import

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
try:
  from Bio import SeqIO
  from Bio import Seq
except:
  !pip install biopython
  from Bio import SeqIO
  from Bio import Seq
import re
import os

# Functions

def filter_seq(curr_seq):
  # returns True if sequences flanking the var region are found, else False
  if (forward_seq_up in curr_seq) and (forward_seq_down in curr_seq):
    return True
#  if (reverse_seq_up in curr_seq) and (reverse_seq_down in curr_seq): # Relevnat to R2
#    return True
  return False

def slice_var_region_R1(curr_seq):

  # for R1. Slices the var region and returns its sequence should it be exactly 36nts long, else returns None

  var_start = re.search(forward_seq_up, curr_seq)
  var_end = re.search(forward_seq_down, curr_seq)
  if var_start == None or var_end == None:
    curr_seq = "g" #if the flanking sequences of var region are not found in the sequence, change it to "a" (to later get rid of it)
  else:
    var_start_index = var_start.span()[1]
    var_end_index = var_end.span()[0]
    var_seq = curr_seq[var_start_index:var_end_index]
    if len(var_seq) == 36:
     return var_seq
    return None


#def slice_var_region_R2(curr_seq):

  # for R2. Slices the var region and returns its sequence should it be exactly 36nts long, else returns None
# var_start = re.search(reverse_seq_up, curr_seq)
#  var_end = re.search(reverse_seq_down, curr_seq)
#  if var_start == None or var_end == None:
#    curr_seq = "g" #if the flanking sequences of var region are not found in the sequence, change it to "a" (to later get rid of it)
#  else:
#    var_start_index = var_start.span()[1]
#    var_end_index = var_end.span()[0]
#    var_seq = curr_seq[var_start_index:var_end_index]
#    if len(var_seq) == 36:
#      return var_seq
#    return None

# Data path and parsing into a pandas DataFrame
filter_stats = pd.DataFrame(columns=['R1', 'R2'])
curr_dir = os.path.dirname(FASTQ_R1_path)
read_list_R1 = []
#read_list_R2 = []

for record in SeqIO.parse(FASTQ_R1_path, "fastq"): # Parse into a list
   read_list_R1.append(str(record.seq))

reads_R1_df = pd.DataFrame(columns=['read_seq'], index=range(len(read_list_R1))) # Create a pandas DataFrame
reads_R1_df['read_seq'] = read_list_R1 # add reads into the df

#for record in SeqIO.parse(FASTQ_R2_path, "fastq"): # Parse into a list
#   read_list_R2.append(str(record.seq))

#reads_R2_df = pd.DataFrame(columns=['read_seq'], index=range(len(read_list_R2))) # Create a pandas DataFrame
#reads_R2_df['read_seq'] = read_list_R2 # add reads into the df

# Filtration according to read length

reads_R1_df['read_length'] = reads_R1_df['read_seq'].apply(len) # Add a column with all read lengths
reads_R1_df = reads_R1_df[reads_R1_df['read_length'] >= 150] # Slice only reads lengths bigger than 150

#reads_R2_df['read_length'] = reads_R2_df['read_seq'].apply(len) # Add a column with all read lengths
#reads_R2_df = reads_R2_df[reads_R2_df['read_length'] >= 150] # Slice only reads lengths bigger than 150

# This stage is not necessary, but aids in getting rid of "bad" reads - e.g., the expected length is 150, then shorter reads are probably bad.

# Filtration of reads that contain desired flanking sequences up and down stream to the var region

reads_R1_df['iscorrect'] = reads_R1_df['read_seq'].apply(filter_seq)
reads_R1_df = reads_R1_df[reads_R1_df.iscorrect]

#reads_R2_df['iscorrect'] = reads_R2_df['read_seq'].apply(filter_seq)
#reads_R2_df = reads_R2_df[reads_R2_df.iscorrect]

# Filtration of sequences that contain a var region of 36 nt only

reads_R1_df['var_seq'] = reads_R1_df['read_seq'].apply(slice_var_region_R1)
reads_R1_df = reads_R1_df[reads_R1_df.var_seq != "g"] # drop rows that do not contain the flanking regions
reads_R1_df = reads_R1_df.dropna() # drop rows that contain var sequence that their length is not equal to 36nts

#reads_R2_df['var_seq'] = reads_R2_df['read_seq'].apply(slice_var_region_R2)
#reads_R2_df = reads_R2_df[reads_R2_df.var_seq != "g"] # drop rows that do not contain the flanking regions
#reads_R2_df = reads_R2_df.dropna() # drop rows that contain var sequence that their length is not equal to 36nts

# This stage needs to be performed only if you use R2 too

# Turn all var region to reverse complement (for R2 only)
#reads_R2_df['var_seq'] = reads_R2_df['var_seq'].apply(Seq.reverse_complement)

# Filtration of comparison between R1 and R2
#shared_index = list(set(reads_R1_df.index.tolist()).intersection(reads_R2_df.index.tolist())) # shared reads indices between R1 and R2
#reads_R1_df = reads_R1_df[reads_R1_df.index.isin(shared_index)]
#reads_R2_df = reads_R2_df[reads_R2_df.index.isin(shared_index)]

# Slice var seqs that are the same for each read
#is_same_var_seq = reads_R1_df['var_seq'] == reads_R2_df['var_seq']
#shared_same_index = is_same_var_seq[is_same_var_seq].index


# Indices of rows that contain the same var seq between R1 and R2
#reads_R1_df = reads_R1_df[reads_R1_df.index.isin(shared_same_index.tolist())]
#reads_R2_df = reads_R2_df[reads_R2_df.index.isin(shared_same_index.tolist())]

nuc_ratio_R1 = reads_R1_df['var_seq'].value_counts() # show # reads for each nuc seq

#nuc_ratio_R2 = reads_R2_df['var_seq'].value_counts() # show # reads for each nuc seq

# Final output table

final_output = pd.DataFrame(columns=['nuc_seq', '#reads', 'reads_ratio'], index=range(nuc_ratio_R1.shape[0]))
final_output['nuc_seq'] = nuc_ratio_R1.index.tolist()
final_output['#reads'] = nuc_ratio_R1.tolist()
final_output['reads_ratio'] = (nuc_ratio_R1 / reads_R1_df.shape[0]).tolist()

final_output.to_csv(os.path.join(curr_dir, 'c3thesis_nucs.csv'))